{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PyPDF2 import PdfReader\n",
    "\n",
    "pdf_folder = \"/Users/anandnishad/Desktop/harry_potter_rag\"\n",
    "\n",
    "pdf_files = sorted([f for f in os.listdir(pdf_folder) if f.endswith(\".pdf\")])\n",
    "\n",
    "# Initialize an empty string to store the combined text\n",
    "text = \"\"\n",
    "for pdf_file in pdf_files:\n",
    "    pdf_path = os.path.join(pdf_folder, pdf_file)\n",
    "    reader = PdfReader(pdf_path)\n",
    "\n",
    "    print(f\"Reading: {pdf_file}\")\n",
    "\n",
    "    for page in reader.pages:\n",
    "        text_1 = page.extract_text()\n",
    "        if text_1:\n",
    "            text += text_1 + \"\\n\\n\" \n",
    "    # print(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(text)\n",
    "def chunk_text(text, chunk_size=500):\n",
    "    words = text.split()\n",
    "    chunks = [\" \".join(words[i:i+chunk_size]) for i in range(0, len(words), chunk_size)]\n",
    "    return chunks\n",
    "\n",
    "text_chunks = chunk_text(text, chunk_size=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(text_chunks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "embeddings = model.encode(text_chunks)  # text_chunks is a list of split text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = embeddings.shape[1] \n",
    "print(embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "\n",
    "index = faiss.IndexFlatL2(embedding_dim)\n",
    "index.add(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load the same embedding model used earlier\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Convert query to an embedding\n",
    "query = \"Who killed Albus Dumbledore\"\n",
    "query_embedding = model.encode([query])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Relevant Chunk:\n",
      "had me use any wizard, would you not, Wormtail? Any wizard who had hated me . . . as so many of them still do. But I knew the one I must use, if I was to rise again, more powerful than I had been when I had fallen. I wanted Harry Potter’s blood. I wanted the blood of the one who had stripped me of power thirteen years ago . . . for the lingering protection his mother once gave him would then reside in my veins too. . . . “But how to get at Harry Potter? For\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Number of closest chunks to retrieve\n",
    "k = 5000  \n",
    "\n",
    "# Perform similarity search\n",
    "distances, indices = index.search(np.array(query_embedding), k)\n",
    "\n",
    "# Retrieve relevant text chunks\n",
    "retrieved_chunks = [text_chunks[i] for i in indices[0]]\n",
    "\n",
    "print(\"Most Relevant Chunk:\")\n",
    "print(retrieved_chunks[0])  # The most relevant text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "\n",
    "def construct_prompt(input_text, refrence_data):\n",
    "\n",
    "    prompt = f\"\"\"the refrence data {refrence_data} my query {input_text}  read refrence_data and answer query form refrence data only esle return insufficent data\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "    return prompt\n",
    "\n",
    "\n",
    "def chat_with_gpt(input_text, group_subgroup_json):\n",
    "    \n",
    "    openai.api_key = \"\"\n",
    "\n",
    "\n",
    "    # Create the prompt\n",
    "    prompt = construct_prompt(input_text, group_subgroup_json)\n",
    "\n",
    "    # Call the API\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4-turbo-2024-04-09\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=0,\n",
    "        top_p=1,\n",
    "    )\n",
    "\n",
    "    # Extract and return the response content\n",
    "    usage = response[\"usage\"]\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snape Killed Albus Dumbledore\n"
     ]
    }
   ],
   "source": [
    "data = chat_with_gpt(query,retrieved_chunks[0])\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install openai==0.28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "adi_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
